# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112Rh7VwsE06bAjbWwDghEJAuaAORC2nx
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
# %matplotlib inline
warnings.filterwarnings('ignore')

df = pd.read_csv('train.csv')
df.head()

# statistical info
df.describe()

# datatype info
df.info()

# find unique values
df.apply(lambda x: len(x.unique()))

# distplot for purchase
plt.style.use('fivethirtyeight')
plt.figure(figsize=(13, 7))
sns.distplot(df['Purchase'], bins=25)

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'Gender' is a column in your DataFrame
sns.countplot(x='Gender', data=df)

# Display the plot
plt.show()

from google.colab import drive
drive.mount('/content/drive')

# Assuming 'Age' is a column in your DataFrame
# Convert 'Age' to a categorical data type
df['Age'] = df['Age'].astype('category')

# Create a count plot for the 'Age' column
sns.countplot(x='Age', data=df)

# Display the plot
plt.show()

# Assuming 'Marital_Status' is a column in your DataFrame
# Convert 'Marital_Status' to a categorical data type
df['Marital_Status'] = df['Marital_Status'].astype('category')

# Create a count plot for the 'Marital_Status' column
sns.countplot(x='Marital_Status', data=df)

# Display the plot
plt.show()

# Assuming 'Occupation' is a column in your DataFrame
# Convert 'Occupation' to a categorical data type
df['Occupation'] = df['Occupation'].astype('category')

# Create a count plot for the 'Occupation' column
plt.figure(figsize=(10, 6))  # Adjust the figure size if needed
sns.countplot(x='Occupation', data=df)

# Display the plot
plt.show()

# Assuming 'Product_Category_1' is a column in your DataFrame
# Convert 'Product_Category_1' to a categorical data type
df['Product_Category_1'] = df['Product_Category_1'].astype('category')
plt.figure(figsize=(10, 6))

# Create a count plot for the 'Product_Category_1' column
sns.countplot(x='Product_Category_1', data=df)

# Display the plot
plt.show()

# Assuming 'Product_Category_2' is a column in your DataFrame
# Convert 'Product_Category_2' to a categorical data type
df['Product_Category_2'] = df['Product_Category_2'].astype('category')
plt.figure(figsize=(10, 6))

# Create a count plot for the 'Product_Category_2' column
sns.countplot(x='Product_Category_2', data=df)

# Display the plot
plt.show()

df['Product_Category_3'] = df['Product_Category_3'].astype('category')
plt.figure(figsize=(10,6))

sns.countplot(x='Product_Category_3',data=df)

plt.show()

df['City_Category']=df['City_Category'].astype('category')
plt.figure(figsize=(10,6))

sns.countplot(x='City_Category',data=df)
plt.show()

df['Stay_In_Current_City_Years']=df['Stay_In_Current_City_Years'].astype('category')
plt.figure(figsize=(10,6))

sns.countplot(x='Stay_In_Current_City_Years',data=df)
plt.show()

# bivariate analysis
occupation_plot = df.pivot_table(index='Occupation', values='Purchase', aggfunc=np.mean)
occupation_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('Occupation')
plt.ylabel("Purchase")
plt.title("Occupation and Purchase Analysis")
plt.xticks(rotation=0)
plt.show()

age_plot = df.pivot_table(index='Age', values='Purchase', aggfunc=np.mean)
age_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('Age')
plt.ylabel("Purchase")
plt.title("Age and Purchase Analysis")
plt.xticks(rotation=0)
plt.show()

gender_plot = df.pivot_table(index='Gender', values='Purchase', aggfunc=np.mean)
gender_plot.plot(kind='bar', figsize=(13, 7))
plt.xlabel('Gender')
plt.ylabel("Purchase")
plt.title("Gender and Purchase Analysis")
plt.xticks(rotation=0)
plt.show()

# check for null values
df.isnull().sum()

df['Product_Category_2'] = df['Product_Category_2'].astype("float32")
df['Product_Category_3'] = df['Product_Category_3'].astype("float32")

df['Product_Category_2'] = df['Product_Category_2'].fillna(-2.0)
df['Product_Category_3'] = df['Product_Category_3'].fillna(-2.0)

df.isnull().sum()

# encoding values using dict
gender_dict = {'F':0, 'M':1}
df['Gender'] = df['Gender'].apply(lambda x: gender_dict[x])
df.head()

# to improve the metric use one hot encoding
# label encoding
cols = ['Age', 'City_Category', 'Stay_In_Current_City_Years']
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in cols:
    df[col] = le.fit_transform(df[col])
df.head()

corr = df.corr()
plt.figure(figsize=(14,7))
sns.heatmap(corr, annot=True, cmap='coolwarm')

df.head()

X = df.drop(columns=['User_ID', 'Product_ID', 'Purchase'])
y = df['Purchase']

from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error
def train(model, X, y):
    # train-test split
    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)
    model.fit(x_train, y_train)

    # predict the results
    pred = model.predict(x_test)

    # cross validation
    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)
    cv_score = np.abs(np.mean(cv_score))

    print("Results")
    print("MSE:", np.sqrt(mean_squared_error(y_test, pred)))
    print("CV Score:", np.sqrt(cv_score))

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

# Create a StandardScaler instance
scaler = StandardScaler()

# Fit and transform the input features
X_scaled = scaler.fit_transform(X)

# Create a LinearRegression model
model = LinearRegression()

# Train the model
model.fit(X_scaled, y)

# Get the coefficients and feature names
coef = pd.Series(model.coef_, index=X.columns).sort_values()

# Plot the coefficients
coef.plot(kind='bar', title='Model Coefficients')

import sklearn
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
train(model, X, y)
features = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)
features.plot(kind='bar', title='Feature Importance')

from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_jobs=-1)
model.fit(X, y)

features = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)
features.plot(kind='bar', title='Feature Importance')

from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor(n_jobs=-1)
model.fit(X, y)

features = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)
features.plot(kind='bar', title='Feature Importance')

pred = model.predict(X)

submission = pd.DataFrame()
submission['User_ID'] = X.index
submission['Purchase'] = pred

submission.to_csv('submission.csv', index=False)

